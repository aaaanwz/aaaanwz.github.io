<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on A4 tech note</title>
    <link>https://aaaanwz.github.io/post/</link>
    <description>Recent content in Posts on A4 tech note</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Fri, 29 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://aaaanwz.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>BERTによるテキスト分類サンプルコード</title>
      <link>https://aaaanwz.github.io/post/2022/bert_example/</link>
      <pubDate>Fri, 29 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2022/bert_example/</guid>
      <description>GPU環境整備 今回はGCE VM + ColabでGPU環境を用意しました。 https://research.google.com/colaboratory/marketplace.html
1 2  !nvcc -V !nvidia-smi   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  +-----------------------------------------------------------------------------+ | NVIDIA-SMI 495.46 Driver Version: 460.32.03 CUDA Version: 11.2 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M.</description>
    </item>
    
    <item>
      <title>sklearn モデル選択とパラメータチューニングのサンプルコード</title>
      <link>https://aaaanwz.github.io/post/2022/decision_tree_classfier/</link>
      <pubDate>Wed, 29 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2022/decision_tree_classfier/</guid>
      <description>データ用意 data.csv
1 2 3  param_a, param_b, label hoge, fuga, 1 foo, bar, 0   1 2 3 4 5 6 7  import pandas as pd from sklearn.model_selection import train_test_split FILENAME=&amp;#39;data.csv&amp;#39; data = pd.read_csv(FILENAME) data[&amp;#39;labels&amp;#39;] = data[&amp;#39;labels&amp;#39;].astype(int)   モデル比較 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  names = [ &amp;#34;Nearest Neighbors&amp;#34;, &amp;#34;Linear SVM&amp;#34;, &amp;#34;RBF SVM&amp;#34;, &amp;#34;Gaussian Process&amp;#34;, &amp;#34;Decision Tree&amp;#34;, &amp;#34;Random Forest&amp;#34;, &amp;#34;Neural Net&amp;#34;, &amp;#34;AdaBoost&amp;#34;, &amp;#34;Naive Bayes&amp;#34;, &amp;#34;QDA&amp;#34;, ] classifiers = [ KNeighborsClassifier(3), SVC(kernel=&amp;#34;linear&amp;#34;, C=0.</description>
    </item>
    
    <item>
      <title>Kinesis Data FirehoseからMongoDB Cloudにデータを流してみる</title>
      <link>https://aaaanwz.github.io/post/2022/firehose_mongo/</link>
      <pubDate>Wed, 02 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2022/firehose_mongo/</guid>
      <description>Amazon Kinesis Data Firehose が MongoDB Cloud へのデータ配信のサポートを開始 したそうなので試してみましたが、色々と「ん？」と思う点があったので書き残します。
MongoDB Atlas でClusterを作成 MongoDB Atlas、MongoDB Realmという単語が登場しますが、AtlasはDBaaSとしてのMongoDBそのもの、RealmはAtlasを操作するためのインターフェースとなるサービスのようです。
まずはAtlasでCluster, Database, Collectionを作成します。
 Get Started with Atlas  MongoDB Realm Functionsを実装 てっきりGUIポチポチで連携完了するものかとおもってましたが、FirehoseからのWebhookエンドポイントとなるサーバーレス関数を自前で実装する必要があります。
だったらKinesis Data Streams + Lambdaでよくね&amp;hellip;？
 MongoDB Realm Functions  リリースノートのリンク先のサンプルコードの冒頭はこんな感じ。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  exports = function(payload, response) { /* Using Buffer in Realm causes a severe performance hit this function is ~6 times faster */ const decodeBase64 = (s) =&amp;gt; { var e={},i,b=0,c,x,l=0,a,r=&amp;#39;&amp;#39;,w=String.</description>
    </item>
    
    <item>
      <title>2021年 エンジニア的に買ってよかったもの</title>
      <link>https://aaaanwz.github.io/post/2022/bestbuy2021/</link>
      <pubDate>Sun, 09 Jan 2022 13:15:22 +0900</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2022/bestbuy2021/</guid>
      <description>仕事(エンジニア/フルリモート)に役立ったかどうか、という観点で備忘的にまとめてみました。
自宅サーバー (自作) サーバーとして使っていたRaspberry piが成仏し、現在どこも在庫が皆無なため代わりにファンレスPCを組みました。スペック的にも物理的な拡張性にも余裕があるためより一層遊べるようになり、結果として大正解。
サブスクのクラウドサービスをセルフホステッドにどんどん切り替えていってるので、スキルアップと家計の両面に大いに貢献しています。
消費電力は25W/hくらい、電気代は月500円弱。 動かしているアプリケーションに関してはまた別記事で書きたい。
   パーツ 型番     M/B BIOSTAR J4105NH   CPU オンボード   MEM CFD W4U2400PS-4GC17 (4GB x 2)   PSU DC-DCコンバータ + 120W ACアダプタ   ストレージ 余っているSSD/HDDいっぱい。合計10TBくらい   ケース 100均の書類ケースに適当にネジ止め    自作キーボード YD60MQ 何個かキーボードを作ってみて得た結論として、
 特殊すぎる配列はメリットに対して切り替えコストが割に合わない 右手でマウスを持ったまま左手で右側のキーを押す事があるため、自分の場合は左右分割だと効率が下がる  という事から、結局HHKB配列の YMDK YD60MQ に落ち着きました。
Cherry MX銀軸が自分にかなりマッチしており、HHKBを使っていたときより指の疲労が低減しました。
LG ウルトラワイドモニター 35WN75C-B 買ったというか、転職サイトから貰った。
4kモニタは既に持っていてこちらの方が解像度は低かった(3440×1440)けど、大きい正方形のウィンドウ2つを横に並べても視野に収まるのが予想以上に便利でメインモニタに昇格しました。
曲面のため光の映り込みが少ないのも便利。
つっぱり棚 サバゲーやる人が銃を飾るのによく使っているアレです。</description>
    </item>
    
    <item>
      <title>Kubernetesに写真サーバーを構築する</title>
      <link>https://aaaanwz.github.io/post/2022/piwigo/</link>
      <pubDate>Tue, 04 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2022/piwigo/</guid>
      <description>2021年6月1日からGoogle Photoの容量が無制限ではなくなり、無料枠は15GBに制限されてしまいました。
完全に音楽サーバーを構築した話の二番煎じですが、自宅k8sに写真サーバーを構築してそちらに移行する事にしました。
デプロイ self-hostedな写真サーバーで最もメジャーなプロダクトはPiwigoの模様。
サクっとyamlを書いてデプロイします。
deployment.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56  apiVersion: apps/v1 kind: Deployment metadata: name: piwigo spec: replicas: 1 selector: matchLabels: app: piwigo template: metadata: labels: app: piwigo spec: containers: - name: piwigo image: lscr.</description>
    </item>
    
    <item>
      <title>おうちKubernetesに音楽ストリーミングサーバー(兼ファイルサーバー)を構築する</title>
      <link>https://aaaanwz.github.io/post/2021/airsonic/</link>
      <pubDate>Thu, 02 Dec 2021 07:00:00 +0900</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2021/airsonic/</guid>
      <description>神(Google)は「Play Music」と言われた。するとGoogle Play Musicがあった。
神はそのUXを見て、良しとされた。
神はまた言われた。「YouTube Musicに移行してください」
UIは使いづらく、バックグラウンド再生できず、ロードは遅くなり、楽曲メタデータは編集できなくなった。
神はお休みになった。
概要 所有している音楽データをアップロードし、インターネット経由で聴くというサービスでしっくりくるものがないため、自宅Kubernetesクラスタに自前で構築してみます。
 家庭内LANからファイルサーバーとして使える ファイルサーバーにアップロードした音楽データをインターネット経由で聴ける ファイルサイズが大きい楽曲はサーバーサイドでリアルタイムに圧縮して配信する  という要件から、以下のような構成にしてみます。
 音楽配信サーバーには Airsonicを使います  Ingress(L7ロードバランサー)経由でインターネットに接続します IngressをTLS終端にします   ファイルサーバーとしてSambaを構築します  Airsonicとストレージを共有します LoadBalancer Service(L4ロードバランサー)経由で家庭内LANに接続し、インターネットからは遮断します    構築 1. Storage まず初めに、Podからホストマシンのストレージを使うためのPersistentVolume(PV)とPersistentVolumeClaim(PVC)を作成します。 今回は node1 の /mnt/hdd に音楽データとメタデータ(設定、アカウント情報など)を永続化するとします。
pv.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62  apiVersion: v1 kind: PersistentVolume metadata: name: music spec: capacity: storage: 1000Gi accessModes: - ReadWriteOnce local: path: /mnt/hdd/music nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: kubernetes.</description>
    </item>
    
    <item>
      <title>Ubuntu desktop初期設定メモ</title>
      <link>https://aaaanwz.github.io/post/2021/ubuntu-desktop-config/</link>
      <pubDate>Sun, 21 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2021/ubuntu-desktop-config/</guid>
      <description>M1 Macに移行する気になれなかったのでメインマシンをx86 + Ubuntu Desktop 20.04にしました。
GPUドライバのインストール 1  $ sudo ubuntu-drivers autoinstall   IME切り替えショートカットを Ctrl + Space に設定  設定 &amp;gt; 地域と言語 &amp;gt; 入力ソース で入力ソースを 日本語(Mozc) のみにする Mozcプロパティ &amp;gt; キー設定 &amp;gt; 編集　で 入力キーがCtrl Spaceのエントリーを削除し、以下のように設定  CapsLockをCtrlに変更 1 2 3  $ sudo vi /etc/default/keyboard ... XKBOPTIONS=&amp;#34;ctrl:nocaps&amp;#34;   日本語ディレクトリを英語化 1  LANG=C xdg-user-dirs-gtk-update   デスクトップとファイルマネージャの間でファイルの移動ができるようにする GNOME拡張のDesktop Icons NG (DING)をインストール https://extensions.gnome.org/extension/2087/desktop-icons-ng-ding/
元々のDesktop Iconsを無効化 デスクトップアイコンが二重に表示されるので、元々の機能を無効化する
1  $ sudo apt install gnome-shell-extension-prefs   メニュー &amp;gt; 拡張機能 でDesktop Iconsをオフにする</description>
    </item>
    
    <item>
      <title>ArgoCD GitOpsにおけるSecret管理</title>
      <link>https://aaaanwz.github.io/post/2021/argocd-vault-plugin/</link>
      <pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2021/argocd-vault-plugin/</guid>
      <description>KubernetesでGitOps運用となると必ず話題になるのがSecretの管理です。
 Sealed Secretsやkubesecなどの手元で暗号化する系 Kubernetes Secrets Store CSI Driverやkubernetes-external-secretsなどの外部シークレットストアから引っ張ってくる系 機密情報だけ別Repoにする  など様々な方法がありますが、学習コストや実運用をイメージするとどのソリューションもしっくり来ませんでした。
そんな中でIBM社が開発しているArgoCD Vault Pluginを触ってみたところ、ArgoCDのデプロイ時にplaceholderをreplaceするという合理的かつシンプルな仕組みで非常に好感触でした。
 2022/02追記: Argo Projectに移管されたようです。 https://argocd-vault-plugin.readthedocs.io/en/stable/
 (上記でいう「外部シークレットストアから引っ張ってくる系」の一種に該当します) ArgoCD Vault Plugin (以下AVP) は日本語の情報が皆無に等しかったため、布教の目的も込めて導入・運用方法を記載します。
テスト AVPはbrewからも導入でき、手元で簡単にテストができます。 シークレットストアはAWS Secrets Mangerを使う前提で解説します。
ローカル環境にインストール (Mac) 1  $ brew install argocd-vault-plugin   AWS Secrets Mangerに機密文字列を登録する 1 2  key: my_secret value: foobar   Kubernetes Manifestを作成する Secretの実装は非常に簡単で、
 アノテーションに参照するSecret Managerのパスを記述する Secret Managerのキー名を&amp;lt;&amp;gt; で囲う  だけでOKです。
1 2 3 4 5 6 7 8  apiVersion: v1 kind: Secret metadata: name: credentials annotations: avp.</description>
    </item>
    
    <item>
      <title>Argo Workflowsの失敗時にデフォルトでSlackに通知する</title>
      <link>https://aaaanwz.github.io/post/2021/argo-workflows-exit-handler/</link>
      <pubDate>Fri, 29 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2021/argo-workflows-exit-handler/</guid>
      <description>Argo workflowsでは Default Workflow Spec を設定する事でワークフローに色々とパッチできる。
以下のようにexit-handlerをworkflowDefaultsにしておくと、ワークフロー側に何も記述せずとも失敗時にSlackに通知できる。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  apiVersion: v1 kind: ConfigMap metadata: name: workflow-controller-configmap data: workflowDefaults: |spec: onExit: exit-handler templates: - name: exit-handler when: &amp;#34;{{workflow.status}} != Succeeded&amp;#34; container: image: curlimages/curl:latest args: [&amp;#34;-X&amp;#34;,&amp;#34;POST&amp;#34;,&amp;#34;-H&amp;#34;,&amp;#39;Content-type: application/json&amp;#39;,&amp;#34;--data&amp;#34;, &amp;#39;{&amp;#34;attachments&amp;#34;: [{&amp;#34;title&amp;#34;:&amp;#34;Workflow status: {{workflow.status}}&amp;#34;,&amp;#34;color&amp;#34;: &amp;#34;danger&amp;#34;,&amp;#34;fields&amp;#34;: [{&amp;#34;title&amp;#34;: &amp;#34;name&amp;#34;, &amp;#34;value&amp;#34;: &amp;#34;{{workflow.name}}&amp;#34;, &amp;#34;short&amp;#34;: true }, {&amp;#34;title&amp;#34;: &amp;#34;url&amp;#34;, &amp;#34;value&amp;#34;: &amp;#34;https://{{inputs.</description>
    </item>
    
    <item>
      <title>embulkをArgo workflowsで実行するTemplate</title>
      <link>https://aaaanwz.github.io/post/2021/argo-workflows-embulk/</link>
      <pubDate>Thu, 28 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2021/argo-workflows-embulk/</guid>
      <description>Argo Workflowsの公式ドキュメントが分かりづらかったので、試しにembulkを実行するテンプレートを作ってみました。
config.ymlはartifactsとして渡します。
Dockerfile 1 2 3 4 5 6 7 8 9 10 11 12 13  FROM openjdk:8-jre-alpine ARG VERSION=latest RUN mkdir -p /root/.embulk/bin \ &amp;amp;&amp;amp; wget -q https://dl.embulk.org/embulk-${VERSION}.jar -O /root/.embulk/bin/embulk \ &amp;amp;&amp;amp; chmod +x /root/.embulk/bin/embulk ENV PATH=$PATH:/root/.embulk/bin RUN apk add --no-cache libc6-compat RUN embulk gem install embulk-input-s3 ENTRYPOINT [&amp;#34;java&amp;#34;, &amp;#34;-jar&amp;#34;, &amp;#34;/root/.embulk/bin/embulk&amp;#34;]   1 2 3  $ EMBULK_VERSION=0.9.23 $ docker build . -t embulk:$EMBULK_VERSION --build-arg VERSION=$EMBULK_VERSION $ docker run -v /path/to/configfile:/config embulk:latest run /config/config.</description>
    </item>
    
    <item>
      <title>[fluetd] S3にアップロードされたキー名でルーティングする</title>
      <link>https://aaaanwz.github.io/post/2021/fluentd-s3-routing/</link>
      <pubDate>Tue, 26 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2021/fluentd-s3-routing/</guid>
      <description>S3にアップロードされたファイルをfluentdでBigQueryにinsertする際、S3キー名に応じてテーブルを振り分けるサンプルを掲載します。 ここではフォーマットはs3://my-bucket/{BigQueryデータセット名}/{テーブル名}/{uuid}.csv.gz とします。
fluent.conf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  &amp;lt;source&amp;gt; tag s3 @type s3 s3_bucket my-bucket s3_region ap-northeast-1 &amp;lt;sqs&amp;gt; queue_name my-queue &amp;lt;/sqs&amp;gt; &amp;lt;/source&amp;gt; &amp;lt;match s3&amp;gt; @type rewrite_tag_filter &amp;lt;rule&amp;gt; key s3_key pattern ^(.</description>
    </item>
    
    <item>
      <title>kubectl logsに任意のログを表示する</title>
      <link>https://aaaanwz.github.io/post/2021/kubectl-logs/</link>
      <pubDate>Wed, 08 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2021/kubectl-logs/</guid>
      <description>kubectl logsはPID1の標準出力を表示するため、直接書き込んでしまえばなんでも表示できる。
1 2 3  $ kubectl exec -it pod-xxx bash # echo &amp;#39;show as stdin&amp;#39; &amp;gt; /proc/1/fd/1 # echo &amp;#39;show as stderr&amp;#39; &amp;gt; /proc/1/fd/2   1 2 3 4  $ kubectl logs pod-xxx show as stdin show as stderr   </description>
    </item>
    
    <item>
      <title>VSCode Remote ContainerからGitHubにssh接続する</title>
      <link>https://aaaanwz.github.io/post/2021/vscode-remote-container-ssh/</link>
      <pubDate>Thu, 02 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2021/vscode-remote-container-ssh/</guid>
      <description>公式ドキュメントの Sharing Git credentials with your containerに色々と記載があるが、非常に簡単なソリューションがあったためメモ
Mac 1 2 3 4 5  $ sudo vi ~/.ssh/config Host github.com AddKeysToAgent yes UseKeychain yes   Windows 1 2 3  &amp;gt; Set-Service ssh-agent -StartupType Automatic &amp;gt; Start-Service ssh-agent &amp;gt; ssh-add $HOME/.ssh/id_rsa   </description>
    </item>
    
    <item>
      <title>自作キーボードYMDK/SP64ビルドログ</title>
      <link>https://aaaanwz.github.io/post/2021/keyboard-sp64/</link>
      <pubDate>Sat, 26 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2021/keyboard-sp64/</guid>
      <description>標準的な配列の分割キーボードをようやく見つけたためAliExpressで購入。 PCBは予めソケット化されており、差し込むだけで完成なので組み立て手順は割愛。
HHKB liteっぽくキーマップを実装。
左スペースキー横は日英切り替え(`Alt + ``)にしてみる。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68  #include QMK_KEYBOARD_H enum layer_names { BASE, // default layer  _FN, // function layer }; enum custom_keycodes { M_KANA = SAFE_RANGE, }; bool process_record_user(uint16_t keycode, keyrecord_t *record) { if (record-&amp;gt;event.</description>
    </item>
    
    <item>
      <title>Airflowで後続のOperatorに配列を渡す</title>
      <link>https://aaaanwz.github.io/post/2021/airflow-xcom/</link>
      <pubDate>Thu, 20 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2021/airflow-xcom/</guid>
      <description>Apache AirflowにおいてOperator間で値を渡すにはXCOMを使用しますが、
 Airflow macroで文字列として取得する PythonOperatorでtask_instanceから取得する  の2通りの方法があります。
しかし、例えば
GoogleCloudStorageListOperatorでファイルのリストを取得 &amp;raquo; GoogleCloudStorageToBigQueryOperator でリストされたファイルをBigQueryにロードする
といったことをやりたい場合、XCOMからファイルのリストを配列として取得しコンストラクタに渡さなければならないためすこし工夫が必要になります。 本稿ではその実装について記載します。
NG 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  ... list_files = GoogleCloudStorageListOperator( task_id=&amp;#39;list_files&amp;#39;, bucket=&amp;#39;my_bucket&amp;#39;, prefix=&amp;#39;path/to/file/&amp;#39;, xcom_push=True, dag=dag ) gcs_to_bigquery = GoogleCloudStorageToBigQueryOperator( task_id=&amp;#39;gcs_to_bigquery&amp;#39;, bucket=&amp;#39;my_bucket&amp;#39;, source_objects=&amp;#34;{{ ti.xcom_pull(task_ids=&amp;#39;list_files&amp;#39;) }}&amp;#34;, destination_project_dataset_table=&amp;#39;project:dataset.table&amp;#39;, autodetect=True, dag=dag ) list_files &amp;gt;&amp;gt; gcs_to_bigquery ...   ファイル名の配列がデシリアライズされた状態で source_objects に渡されてしまうため動作しません。</description>
    </item>
    
    <item>
      <title>KubernetesのCronJobからJobを手動作成する</title>
      <link>https://aaaanwz.github.io/post/2020/k8s-cron-rerun/</link>
      <pubDate>Mon, 30 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2020/k8s-cron-rerun/</guid>
      <description>1  kubectl create job 作成するJob名 --from=cronjob/CronJob名   https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#-em-job-em-</description>
    </item>
    
    <item>
      <title>terraform非対応リソースをlocal-execで管理する</title>
      <link>https://aaaanwz.github.io/post/2020/terraform-local-exec/</link>
      <pubDate>Mon, 14 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2020/terraform-local-exec/</guid>
      <description>terraformに対応していないクラウドリソースを local-exec を用いてterraform化してみます。 今回はBigQueryのユーザー定義関数(UDF)でやってみます。
実装 さて早速。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  variable project{} resource &amp;#34;null_resource&amp;#34; &amp;#34;bigquery-udf&amp;#34; { &amp;lt;-#1  triggers = { query = &amp;#34;CREATE OR REPLACE FUNCTION my_dataset.TEST_FUNCTION(x INT64) AS (x + 1);&amp;#34; &amp;lt;-#2  } provisioner &amp;#34;local-exec&amp;#34; { &amp;lt;-#3  interpreter = [&amp;#34;bq&amp;#34;, &amp;#34;query&amp;#34;, &amp;#34;--use_legacy_sql=false&amp;#34;, &amp;#34;--project_id=${var.project}&amp;#34;] &amp;lt;-#4  command = self.triggers.query on_failure = fail &amp;lt;-#5  } provisioner &amp;#34;local-exec&amp;#34; { when = destroy &amp;lt;-#6  interpreter = [&amp;#34;bq&amp;#34;, &amp;#34;query&amp;#34;, &amp;#34;--use_legacy_sql=false&amp;#34;, &amp;#34;--project_id=${var.</description>
    </item>
    
    <item>
      <title>GCPでカスタムロールをサービスアカウントにbindingしようとしてエラーになる場合</title>
      <link>https://aaaanwz.github.io/post/2020/gcp-serviceaccount-error/</link>
      <pubDate>Tue, 03 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2020/gcp-serviceaccount-error/</guid>
      <description>1 2 3 4  $ gcloud projects add-iam-policy-binding myproject --member=serviceAccount:myserviceaccount@myproject.iam.gserviceaccount.com --role=&amp;#39;roles/mycustomrole&amp;#39; ERROR: Policy modification failed. For a binding with condition, run &amp;#34;gcloud alpha iam policies lint-condition&amp;#34; to identify issues in condition. ERROR: (gcloud.projects.add-iam-policy-binding) INVALID_ARGUMENT: Role roles/mycustomrole is not supported for this resource.   --role の指定を roles/mycustomrole ではなく projects/myproject/roles/mycustomroleにすればOK
1 2 3  $ gcloud projects add-iam-policy-binding myproject --member=serviceAccount:myserviceaccuont@myproject.iam.gserviceaccount.com --role=&amp;#39;projects/myproject/roles/mycustomrole&amp;#39; Updated IAM policy for project [myproject].   </description>
    </item>
    
    <item>
      <title>自作キーボード JJ50 ビルドログ</title>
      <link>https://aaaanwz.github.io/post/2020/keyboard-jj50/</link>
      <pubDate>Sun, 23 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2020/keyboard-jj50/</guid>
      <description>HHKB Professionalを終のキーボードにしようと思っていましたが、
 長時間コーディングをしていると小指が痛くなる なんだかんだ矢印キーは欲しい  という事で、最近流行りの自作キーボードをやってみようかという運びになりました。
パーツ購入  1 ~ = が上段に並んでいて欲しい 小指で押していたShift、Enter、Deleteを親指付近に移動させたい  という理由によりサイズは12列5行に決定、このサイズのPCBを探したところAliExpressで JJ50 という製品を見つけました。
同時にステンレス製ケース、キーキャップ、CherryMX銀軸を購入。
総額は¥14800(PCB¥3700、ケース¥4100、キーキャップ¥3600、スイッチ¥3400)程度でした。
説明書なんてものは当然ありません。ドキュメントの類はこれが全て。
組み立て   ケースにスイッチを取り付ける
  PCBを載せて半田付け
  キーキャップを取り付けてハードウェアは完成
  表面実装部品は予めついていたため拍子抜けするほど簡単でした。
ファームウェア焼き ビルド環境セットアップ (Mac) 1 2 3 4  $ git clone https://github.com/qmk/qmk_firmware $ cd qmk_firmware $ util/qmk_install.sh $ make git-submodule   キーマップの作成 マクロや３つ以上のレイヤーは使う予定が無いので、とてもシンプルなコードです。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  #include QMK_KEYBOARD_H #define ______ KC_TRNS #define _DEFLT 0 #define _FN 1  bool process_record_user(uint16_t keycode, keyrecord_t *record) { return true; }; const uint16_t PROGMEM keymaps[][MATRIX_ROWS][MATRIX_COLS] = { /* Default * ,-----------------------------------------------------------------------------------.</description>
    </item>
    
    <item>
      <title>BigQueryで重複レコードを削除するSQL</title>
      <link>https://aaaanwz.github.io/post/2020/bigquery-deduplication/</link>
      <pubDate>Wed, 05 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2020/bigquery-deduplication/</guid>
      <description>オペミスやat-least-onceセマンティクスによってINSERTされてしまった重複レコードを消すSQLです。
完全に同一な重複レコードを消す やる事は
 重複レコードのうち最古のものを一時テーブルに退避 重複レコードを全て削除 一時テーブルから再度INSERT です。  Schema
1 2 3 4 5 6 7 8 9 10 11 12  [ { &amp;#34;mode&amp;#34;: &amp;#34;REQUIRED&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;id&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;INTEGER&amp;#34; }, { &amp;#34;mode&amp;#34;: &amp;#34;NULLABLE&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;value&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;STRING&amp;#34; } ]   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  CREATE TABLE project_name.</description>
    </item>
    
    <item>
      <title>Apache beam サンプルコード</title>
      <link>https://aaaanwz.github.io/post/2020/apache-beam-example/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2020/apache-beam-example/</guid>
      <description>Apache beamのJava quickstartがいまいち分かりづらかったため、最小コードとデプロイ手順(Google Cloud Dataflow, AWS EMR)を備忘録としてまとめる
WordCountサンプル https://github.com/aaaanwz/beam-wordcount-sample
1 2 3 4 5 6 7 8 9 10  . ├── pom.xml └── src └── main └── java ├── core │ └── WordCount.java └── dafn ├── ExtractWordsFn.java └── FormatAsTextFn.java   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105  &amp;lt;?</description>
    </item>
    
    <item>
      <title>CircleCIでDeploy Keyを用いて別のprivate repoをcloneする</title>
      <link>https://aaaanwz.github.io/post/2019/circleci-deploy-key/</link>
      <pubDate>Thu, 28 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2019/circleci-deploy-key/</guid>
      <description> ssh-keygenコマンドで公開鍵/秘密鍵を生成する 公開鍵(id_rsa.pub)をGitHubのDeploy keyに登録する 秘密鍵(id_rsa)をCircleCIに登録する 3.のfingerprintを↓にコピー  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  version: 2.1 jobs: do-something-with-another-repository: docker: - image: circleci/golang:1.11-stretch steps: - add_ssh_keys: fingerprints: - &amp;#34;aa:bb:cc:dd:ee:ff:gg:hh:ii:jj:kk:ll:mm:nn:oo:pp&amp;#34; - run: GIT_SSH_COMMAND=&amp;#34;ssh -o StrictHostKeyChecking=no&amp;#34; git clone git@github.com:aaaanwz/another-repository.git - run: echo &amp;#39;Do something&amp;#39; workflows: test: jobs: - do-something-with-another-repository   </description>
    </item>
    
    <item>
      <title>Github ActionsでAWS Lambdaにデプロイする</title>
      <link>https://aaaanwz.github.io/post/2019/github-actions-lambda-deploy/</link>
      <pubDate>Thu, 28 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2019/github-actions-lambda-deploy/</guid>
      <description>GitHubでreleaseが作成された時、Lambdaにコードを反映させバージョンを更新するワークフローの単純な実装です
サンプルディレクトリ構成 1 2 3 4 5 6 7  some-lambda-function-repo ├── .github │ └── workflows │ └── lambda-cd.yml ├── README.md ├── bootstrap └── handler.sh   GitHubのSecretsに以下を設定  AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY  必要なPolicyに関しては割愛します
Github Actions 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  name: Lambda Continuous Delivery on: push: tags: - &amp;#39;*&amp;#39; jobs: lambda-cd: runs-on: ubuntu-latest steps: - uses: actions/checkout@master - run: chmod u+x * - run: zip -r /tmp/some-lambda-function.</description>
    </item>
    
    <item>
      <title>mavenプロジェクト作成からCIOps構築まで</title>
      <link>https://aaaanwz.github.io/post/2019/java-create-maven-project/</link>
      <pubDate>Wed, 24 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2019/java-create-maven-project/</guid>
      <description>git branchに変更が加わった際、
 JUnit test (with MySQL) docker build Kubernetes環境にデプロイ (CIOps)  が行われるJavaプロジェクトを構築します。
 本番運用ではArgoCDなどgitOps構築をお勧めします
 登場するもの OSS  Maven MySQL Docker  サービス  GitHub CircleCI AWS (ECR, EKS) ⇦ 微修正でその他マネージドk8sにも応用可能かと思います。  サンプルプロジェクトの実装 最終的にディレクトリ構成はこんな感じになります。順を追って作っていきます。 GitHubからcloneして頂いても結構です。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  testproject/ ├ src/ │ ├ main/ │ │ └ java/ │ │ └testpackage/ │ │ └Main.java │ └ test/ │ └ java/ │ └testpackage/ │ └MainTest.</description>
    </item>
    
    <item>
      <title>Kubernetes Liveness ProbeでJavaプロセスを監視する</title>
      <link>https://aaaanwz.github.io/post/2019/java-k8s-liveness-probe/</link>
      <pubDate>Tue, 02 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2019/java-k8s-liveness-probe/</guid>
      <description>Javaプロセスを一定時間毎にチェックし、ハングしていればPodを再起動する仕組みの備忘録です。
Kubernetes LivenessProbeに関する詳細はこちらをご参照ください。
Java実装 監視対象クラス テスト用に、インスタンスが生成されてから10秒後に isAlive() == falseになるように実装します。
1 2 3 4 5 6 7 8 9 10  public class SomeResource { final long createdTime; public SomeResource() { this.createdTime = System.currentTimeMillis(); } public boolean isAlive() { return System.currentTimeMillis() - createdTime &amp;lt; 10000; } }   監視用エンドポイント SomeResource#isAlive() == trueの時はレスポンスコード 200, falseの時は 500を返すように実装します。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  import com.</description>
    </item>
    
    <item>
      <title>Javaで文字コードを推測する</title>
      <link>https://aaaanwz.github.io/post/2019/juniversalchardet/</link>
      <pubDate>Thu, 27 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2019/juniversalchardet/</guid>
      <description>juniversalchardetを使用して、
 ファイルの文字コードを推測・デコード・コンソールへの表示を行う URLエンコードされた文字列をデコードする  の2つのサンプルプログラムを作成してみます。
juniversalchardetとはMozillaによって提供されているライブラリで、バイト列のパターンの出現頻度をもとに文字コードを推測する機能を提供します。現在日本語ではISO-2022-JP, SHIFT-JIS, EUC-JPに対応しています。
開発環境  OpenJDK 11 Maven 3.6  下準備 以下をmaven dependenciesに追加します
1 2 3 4 5  &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.googlecode.juniversalchardet&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;juniversalchardet&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.0.3&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt;   サンプル1. ファイル読み込み Detectorクラス 今回は汎用性のためにInputStreamを引数としてみます。 引数に渡されたInputStreamインスタンスはオフセットが進んでしまう事に注意が必要です。 UniversalDetectorは入力データが全てシングルバイト文字の場合は文字コード判定結果がnullとなります。今回はそのような場合は環境デフォルト値を返すようにしました。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  import java.</description>
    </item>
    
    <item>
      <title>Kafka Streams DSLを一通り体験する (3. ステートフル処理実践編)</title>
      <link>https://aaaanwz.github.io/post/2019/kafkastreams-3/</link>
      <pubDate>Fri, 07 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2019/kafkastreams-3/</guid>
      <description>Kafka Streams DSLのうち、ステートフルな操作(join,reduce,aggregate,windowingなど)を実際に触り、動作を確認します。
また最後に、本稿と前回で登場した関数を使用してステートフルなストリームFizzBuzzを実装してみます。
実際にやってみる 前々回の記事(準備編)のプロジェクトが作成済みである事を前提とします。
KTable まずはじめに、KTable,KGroupedStreamについて知っておく必要があります。 KGroupedStreamはkeyの値毎にグループ化されたKStreamで、KTableはkeyとvalueの最新状態を保持するテーブルとして扱えるものです。
KTableはnew StreamsBuilder().table(&amp;quot;topic-name&amp;quot;)...のように直接トピックから生成したり、KGroupedStreamを集約して生成したりと様々なルートで生成することができます。
公式ドキュメントの以下の図が非常に分かりやすいです。
画像リンク元ページ
Aggregate KGroupedStreamをkeyごとに集約し、KTableに変換します。 コードと実行結果を見るのが一番早いと思います。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  private static Initializer&amp;lt;String&amp;gt; initializer = () -&amp;gt; &amp;#34;InitVal&amp;#34;; private static Aggregator&amp;lt;String, String, String&amp;gt; aggregator = (key, val, agg) -&amp;gt; agg + &amp;#34; &amp;amp; &amp;#34; + val; public static Topology getTopology() { StreamsBuilder builder = new StreamsBuilder(); builder .</description>
    </item>
    
    <item>
      <title>Kafka Streams DSLを一通り体験する (2. ステートレス処理実践編)</title>
      <link>https://aaaanwz.github.io/post/2019/kafkastreams-2/</link>
      <pubDate>Wed, 05 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2019/kafkastreams-2/</guid>
      <description>Kafka Streams DSLのうち、ステートレスな操作(branch,map,mergeなど)を実際に触り、動作を確認します。 また最後に、本稿で登場する関数を使用してストリーム処理のFizzBuzzを実装してみます。
前回の記事(準備編)のプロジェクトが作成済みである事を前提とします。
実際にやってみる Filter Java StreamのByPredicateと同じと思って差し支えありません。Java StreamのPredicateと紛らわしいのでimport対象に注意しましょう。
key, valueを引数にbooleanを返し、falseの場合はレコードが除外されます。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  import org.apache.kafka.streams.kstream.Predicate; ... private static Predicate&amp;lt;String, String&amp;gt; predicate = (key, value) -&amp;gt; value.startsWith(&amp;#34;あ&amp;#34;); public static Topology getTopology() { StreamsBuilder builder = new StreamsBuilder(); builder .stream(&amp;#34;input-topic&amp;#34;, Consumed.with(Serdes.String(), Serdes.String())) //使用するデシリアライザにStringを明示指定します .filter(predicate) .to(&amp;#34;output-topic&amp;#34;); return builder.build(); }   ここでConsumed.with(...)が新たに登場しました。Predicateの引数がString型なので、デシリアライザも明示指定する必要があるためです。
また.filter((key, value)-&amp;gt; value.startsWith(&amp;quot;あ&amp;quot;))のように直接ラムダ式を記述することももちろん可能です。
さて、テストを実行してみましょう。
1 2 3 4 5 6 7  @Test void test() { inputRecord(&amp;#34;input-topic&amp;#34;, &amp;#34;key1&amp;#34;, &amp;#34;あけまして&amp;#34;); System.</description>
    </item>
    
    <item>
      <title>Kafka Streams DSLを一通り体験する(1. 準備編)</title>
      <link>https://aaaanwz.github.io/post/2019/kafkastreams-1/</link>
      <pubDate>Tue, 04 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://aaaanwz.github.io/post/2019/kafkastreams-1/</guid>
      <description>Kafka Streamsを使ってステートフルなストリーム処理を実装したいと思い立ったものの、Kafka Streams Developer guideを読んでもいまいちよくわからなかったため、自分で一通り試してみました。
この記事ではAggregate Reduce Join Windowingなど、Kafka Streams DSLでできる事を順番にテストし、挙動を確認していきます。また、kafka-streams-test-utilsを用いたJUnitの実装についても解説します。
開発環境  OpenJDK 11 Maven 3.6 Kafka 2.1.1  下準備 プロジェクトの作成 以下の依存関係を追加します
 kafka-streams kafka-streams-test-utils junit-jupiter-api junit-jupiter-engine maven-surefire-plugin  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  &amp;lt;project xmlns=&amp;#34;http://maven.</description>
    </item>
    
  </channel>
</rss>
